{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a92223-5d91-4c3f-b827-9873d3f6cff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sizheliu/miniconda3/envs/unsloth/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-13 11:06:28 [__init__.py:241] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\", \"tissuenarrator\")))\n",
    "\n",
    "from llm import VLLMWrapper\n",
    "from evaluator import SpatialEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5edfb311-8fa9-4e3a-8d12-7200e976a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"/home/sizheliu/spatial-text/data/merfish/merfish_central_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f76aa3f7-8492-4ebd-a038-9006dbe652fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;pos&gt; X: 756, Y: 3593 &lt;meta&gt; class: IT-ET Glut...</td>\n",
       "      <td>&lt;pos&gt; X: 589, Y: 3666 &lt;meta&gt; class: CNU-HYa Gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;pos&gt; X: 692, Y: 3931 &lt;meta&gt; class: Immune, sp...</td>\n",
       "      <td>&lt;pos&gt; X: 577, Y: 4041 &lt;meta&gt; class: Vascular, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;pos&gt; X: 925, Y: 4919 &lt;meta&gt; class: OPC-Oligo,...</td>\n",
       "      <td>&lt;pos&gt; X: 935, Y: 5117 &lt;meta&gt; class: OB-CR Glut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;pos&gt; X: 859, Y: 4220 &lt;meta&gt; class: IT-ET Glut...</td>\n",
       "      <td>&lt;pos&gt; X: 887, Y: 4401 &lt;meta&gt; class: CTX-CGE GA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;pos&gt; X: 802, Y: 4052 &lt;meta&gt; class: Immune, sp...</td>\n",
       "      <td>&lt;pos&gt; X: 842, Y: 4246 &lt;meta&gt; class: CTX-CGE GA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  <pos> X: 756, Y: 3593 <meta> class: IT-ET Glut...   \n",
       "1  <pos> X: 692, Y: 3931 <meta> class: Immune, sp...   \n",
       "2  <pos> X: 925, Y: 4919 <meta> class: OPC-Oligo,...   \n",
       "3  <pos> X: 859, Y: 4220 <meta> class: IT-ET Glut...   \n",
       "4  <pos> X: 802, Y: 4052 <meta> class: Immune, sp...   \n",
       "\n",
       "                                              answer  \n",
       "0  <pos> X: 589, Y: 3666 <meta> class: CNU-HYa Gl...  \n",
       "1  <pos> X: 577, Y: 4041 <meta> class: Vascular, ...  \n",
       "2  <pos> X: 935, Y: 5117 <meta> class: OB-CR Glut...  \n",
       "3  <pos> X: 887, Y: 4401 <meta> class: CTX-CGE GA...  \n",
       "4  <pos> X: 842, Y: 4246 <meta> class: CTX-CGE GA...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_prompt_answer_toy(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[\"answer\"] = out[\"central_sentence\"].astype(\"string\")\n",
    "    out[\"prompt\"] = out[\"neighbor_sentence\"].astype(\"string\")\n",
    "    return out\n",
    "    \n",
    "df = build_prompt_answer_toy(df)\n",
    "df[[\"prompt\", \"answer\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4adeb95-d84a-4d33-80b6-31025bc7f2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-13 11:06:35 [utils.py:326] non-default args: {'model': '/home/sizheliu/spatial-text/unsloth/analysis/merfish_epoch_3_28379', 'max_model_len': 32000, 'disable_log_stats': True}\n",
      "INFO 11-13 11:06:42 [__init__.py:711] Resolved architecture: Qwen3ForCausalLM\n",
      "INFO 11-13 11:06:42 [__init__.py:1750] Using max model len 32000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 11:06:42,381\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-13 11:06:42 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 11-13 11:06:42 [__init__.py:2921] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized\n",
      "INFO 11-13 11:06:48 [__init__.py:241] Automatically detected platform cuda.\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:06:49 [core.py:636] Waiting for init message from front-end.\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:06:49 [core.py:74] Initializing a V1 LLM engine (v0.10.1.1) with config: model='/home/sizheliu/spatial-text/unsloth/analysis/merfish_epoch_3_28379', speculative_config=None, tokenizer='/home/sizheliu/spatial-text/unsloth/analysis/merfish_epoch_3_28379', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/sizheliu/spatial-text/unsloth/analysis/merfish_epoch_3_28379, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":1,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:06:50 [parallel_state.py:1134] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m WARNING 11-13 11:06:50 [topk_topp_sampler.py:61] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:06:50 [gpu_model_runner.py:1953] Starting to load model /home/sizheliu/spatial-text/unsloth/analysis/merfish_epoch_3_28379...\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:06:50 [gpu_model_runner.py:1985] Loading model from scratch...\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:06:50 [cuda.py:328] Using Flash Attention backend on V1 engine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:11<00:11, 11.46s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:18<00:00,  8.71s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:18<00:00,  9.12s/it]\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:07:09 [default_loader.py:262] Loading weights took 18.31 seconds\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:07:10 [gpu_model_runner.py:2007] Model loading took 7.5532 GiB and 19.212482 seconds\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:07:19 [backends.py:548] Using cache directory: /home/sizheliu/.cache/vllm/torch_compile_cache/08e58c8bea/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:07:19 [backends.py:559] Dynamo bytecode transform time: 9.52 s\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:07:30 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 10.405 s\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:07:31 [monitor.py:34] torch.compile takes 9.52 s in total\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:07:33 [gpu_worker.py:276] Available KV cache memory: 33.69 GiB\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:07:33 [kv_cache_utils.py:849] GPU KV cache size: 245,296 tokens\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:07:33 [kv_cache_utils.py:853] Maximum concurrency for 32,000 tokens per request: 7.67x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 67/67 [00:03<00:00, 20.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:07:37 [gpu_model_runner.py:2708] Graph capturing finished in 3 secs, took 0.61 GiB\n",
      "\u001b[1;36m(EngineCore_0 pid=1328618)\u001b[0;0m INFO 11-13 11:07:37 [core.py:214] init engine (profile, create kv cache, warmup model) took 27.10 seconds\n",
      "INFO 11-13 11:07:37 [llm.py:298] Supported_tasks: ['generate']\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"/home/sizheliu/spatial-text/unsloth/analysis/merfish_epoch_3_28379\"\n",
    "model = VLLMWrapper(MODEL_PATH, max_length=32000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c13df3b-8a26-4263-bd6e-f900d9ef6cf8",
   "metadata": {},
   "source": [
    "### Inference Modes\n",
    "\n",
    "- **meta_all** — Uses both the neighbor sentence and the target cell’s metadata.  \n",
    "- **meta_neighbor** — Uses only the neighbor sentence’s metadata.  \n",
    "- **pos_only** — Excludes all metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "246bffe5-01a0-417d-9abf-b91a80bdbb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Adding requests:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Adding requests: 100%|██████████| 10/10 [00:00<00:00, 54.89it/s][A\n",
      "\n",
      "Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts:  10%|█         | 1/10 [00:36<05:24, 36.01s/it, est. speed input: 214.85 toks/s, output: 11.11 toks/s]\u001b[A\n",
      "Processed prompts:  40%|████      | 4/10 [00:36<00:41,  6.86s/it, est. speed input: 1033.36 toks/s, output: 44.22 toks/s]\u001b[A\n",
      "Processed prompts:  60%|██████    | 6/10 [00:36<00:15,  3.91s/it, est. speed input: 2033.85 toks/s, output: 66.01 toks/s]\u001b[A\n",
      "Processed prompts:  80%|████████  | 8/10 [00:36<00:04,  2.43s/it, est. speed input: 2983.71 toks/s, output: 87.74 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 10/10 [00:36<00:00,  3.66s/it, est. speed input: 3900.98 toks/s, output: 109.43 toks/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:36<00:00,  3.68s/it]\n"
     ]
    }
   ],
   "source": [
    "per_row_model, overall_model, gen_blocks = SpatialEvaluator(model).evaluate_prompt_df(\n",
    "    df,\n",
    "    max_rows=10,\n",
    "    top_k_list=(10, 30, 50),\n",
    "    greedy=False,\n",
    "    batch_size=50,\n",
    "    temperature=0.3,\n",
    "    top_k=20,\n",
    "    max_new_tokens=400,\n",
    "    mode=\"meta_all\",\n",
    "    total_prompt_cells=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9f90f22-41d8-41ca-a9dd-0f535671fd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pos> X: 589, Y: 3666 <meta> class: CNU-HYa Glut, spatial_domain: unassigned <cs> GFAP IGF2 ZIC1 SLC7A11 GJA1 NBL1 RANBP3L SLC5A5 ZIC2 COLEC12 BMP6 FBLN1 SLC38A1 ADAM12 SPP1 FGF11 ISYNA1 MAF POU3F3 PADI2 LPAR1 ZIC4 NR2F1 RREB1 NFIX FAM107A AQP4 SLC9A3R1 OSR1 FGF13 GPRC5B PTPN14 ZFP536 BMP4 FZD2 CGNL1 FGF1 SERPINF1 ADRA2A WLS SVEP1 LRP4 LAMA1 COL5A1 SULF2 EYA1 ZFHX4 ID4 ADAMTS2 RAI14 PDE1A FAM43A S1PR1 NTSR2 GPR37L1 TSHZ1 CCN2 SSTR1 COL26A1 DDR2 PTPRU PARM1 ZBTB16 EPHA10 GPC3 NPY1R RGS16 PAX6 LAMA4 ADGRL2 SALL1 KIT C130074G19RIK TNS1 ZFP521 SLC17A7 EYA2 ADAMTS9 C1QL3 ZIC5 SLC7A10 NTRK3 RARB FMO1 SFRP1 HOPX FAM20A POU3F2 ANXA2 GDA SOX9 DCN TSHZ2 GPR4 ITIH5 FAT4 CPNE2 LHX2 C1QTNF7 LYPD6B LYPD6 BOC PCDH18 EPHA7 RASGRP2 ARHGAP28 </cs\n"
     ]
    }
   ],
   "source": [
    "print(gen_blocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72fa86ab-f059-4656-832a-51dd234395cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ndcg': np.float64(0.8739881663260671), 'top_10_overlap': np.float64(0.43), 'top_10_ndcg': np.float64(0.7821181882224029), 'top_30_overlap': np.float64(0.3933333333333333), 'top_30_ndcg': np.float64(0.8002663409995548), 'top_50_overlap': np.float64(0.41800000000000004), 'top_50_ndcg': np.float64(0.8437730743275591)}\n"
     ]
    }
   ],
   "source": [
    "print(overall_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
